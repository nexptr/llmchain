syntax = "proto3";

package local;
option go_package = "github.com/nexptr/llmchain/llms/local";


service ChatService {
    rpc Completion(Request) returns (Respone) {}

    rpc Chat(Request) returns (stream Respone) {}

    rpc Embedings(EmbedingsMessage) returns (EmbedingsResp) {}
}

message Request {
    string prompt = 1;
    float temperature = 2;
    float repetition_penalty = 3;
    float top_p = 4;
    int32 top_k = 5;
	int32 max_new_tokens = 6;
    int32 n = 7;
    bool echo = 8;
    string stop = 9;
    repeated string stop_token_ids = 10;
}

message Respone {
    ErrorCode error_code = 1;
    string text = 2;
    TokenUsage usage = 3;
    string finish_reason = 4;
}

message TokenUsage {
    int32 prompt_tokens = 1;
    int32 completion_tokens = 2;
    int32 total_tokens = 3;
}

enum ErrorCode {
    Zero = 0;
    OutOfMemory = 1;
    Internal = 2;
}


message EmbedingsMessage {
    repeated string prompt = 1;
}

message EmbeddingData {
    repeated float embedding = 1;
}

message EmbedingsResp {
    ErrorCode error_code = 1;
    repeated EmbeddingData Embeddings = 2;
    int32 token_num = 3;
}
